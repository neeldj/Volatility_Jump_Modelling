{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjH1GIn-Drrh",
        "outputId": "f693ca75-1cc2-40ae-db71-75d1fac700e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from hmmlearn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.5.0)\n",
            "Downloading hmmlearn-0.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.9/165.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.3\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xx5Oq5HG_oXG",
        "outputId": "50bfb9e8-0c1c-4b7f-98bc-6b094e06cf0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading CSV data: [Errno 2] No such file or directory: '/content/NYFANG_1min.txt'\n",
            "Failed to fetch valid data\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from hmmlearn import hmm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime, timedelta\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "def load_csv_data(file_path):\n",
        "    \"\"\"Loads market data from a CSV file.\"\"\"\n",
        "    try:\n",
        "        data =  data = pd.read_csv(file_path, header=None, names=[\"Datetime\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"], parse_dates=[\"Datetime\"], index_col=\"Datetime\")\n",
        "        if data.empty:\n",
        "            raise ValueError(\"CSV file is empty or improperly formatted.\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CSV data: {e}\")\n",
        "        return None\n",
        "\n",
        "def calculate_log_returns(data):\n",
        "    \"\"\"Calculates log returns with proper handling\"\"\"\n",
        "    data['LogReturns'] = np.log(data['Close']).diff().dropna()\n",
        "    return data.dropna()\n",
        "\n",
        "# 2. Volatility Estimation (Corrected MedRV)\n",
        "def calculate_medrv(returns, window=20):\n",
        "    \"\"\"Proper MedRV implementation for 15m data\"\"\"\n",
        "    medrv_values = []\n",
        "    for i in range(0, len(returns), window):\n",
        "        window_returns = returns.iloc[i:i+window]\n",
        "        if len(window_returns) < 3:\n",
        "            continue  # Skip incomplete windows\n",
        "\n",
        "        squared_returns = window_returns ** 2\n",
        "        medians = squared_returns.rolling(3, min_periods=3).median().dropna()\n",
        "        if len(medians) < 1:\n",
        "            continue\n",
        "\n",
        "        medrv = (np.pi / (6 - 4*np.sqrt(3) + np.pi)) * np.sum(medians) / (len(medians) - 2)\n",
        "        medrv_values.extend([medrv] * len(window_returns))\n",
        "\n",
        "    return pd.Series(medrv_values[:len(returns)], index=returns.index, name='MedRV')\n",
        "\n",
        "# 3. HMM Implementation with Data Checks\n",
        "def create_hmm(n_components, features):\n",
        "    \"\"\"Creates HMM with validation checks\"\"\"\n",
        "    if len(features) < 10:  # Minimum data points check\n",
        "        raise ValueError(\"Insufficient data for HMM training\")\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    model = hmm.GaussianHMM(\n",
        "        n_components=n_components,\n",
        "        covariance_type=\"diag\",\n",
        "        n_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "    model.fit(scaled_features)\n",
        "    return model, scaler\n",
        "\n",
        "def ait_sahalia_jacod_test(returns):\n",
        "    \"\"\"Determines whether jumps are of finite or infinite activity.\"\"\"\n",
        "    delta = max(2, len(returns) // 10)  # Ensure delta is at least 2\n",
        "    RV_delta = np.sum(returns[::delta]**2)\n",
        "    RV_half_delta = np.sum(returns[::(delta // 2)]**2)\n",
        "\n",
        "    ratio = RV_delta / RV_half_delta if RV_half_delta != 0 else np.nan\n",
        "\n",
        "    if np.isnan(ratio):\n",
        "        return \"Undetermined\"\n",
        "    elif ratio < 1:\n",
        "        return \"Infinite Activity Jumps\"\n",
        "    else:\n",
        "        return \"Finite Activity Jumps\"\n",
        "\n",
        "# 4. Main Execution with Error Handling\n",
        "def main(file_path, n_states=3):\n",
        "    # Fetch data with automatic date adjustment\n",
        "    data = load_csv_data(file_path)\n",
        "    if data is None or data.empty:\n",
        "        print(\"Failed to fetch valid data\")\n",
        "        return\n",
        "\n",
        "    # Feature engineering\n",
        "    data = calculate_log_returns(data)\n",
        "    data['MedRV'] = calculate_medrv(data['LogReturns'])\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    if len(data) < 10:  # Check sufficient data after processing\n",
        "        print(\"Insufficient data after processing\")\n",
        "        return\n",
        "\n",
        "    # Prepare features\n",
        "    features = data[['LogReturns', 'MedRV']]\n",
        "    # HMM training\n",
        "    model, scaler = create_hmm(n_components=n_states, features=features)\n",
        "    states = model.predict(scaler.transform(features))\n",
        "\n",
        "        # Jump detection\n",
        "    state_volatilities = [np.sqrt(cov[0]) for cov in model.covars_]\n",
        "    jump_state = np.argmax(state_volatilities)\n",
        "    data['JumpSignal'] = (states == jump_state).astype(int)\n",
        "    data['JumpType'] = data.apply(lambda row: ait_sahalia_jacod_test(data.loc[:row.name, 'LogReturns'].dropna().values) if row['JumpSignal'] == 1 else 'No Jump', axis=1)\n",
        "    log_table = data[['JumpSignal','JumpType', 'MedRV']]\n",
        "    print(\"\\nJump Log Table:\\n\", tabulate(log_table[log_table['JumpSignal'] == 1], headers='keys', tablefmt='pretty'))\n",
        "    print(\"Finite = \", len(log_table[log_table['JumpType'] == 'Finite Activity Jumps']))\n",
        "    print(\"Infinite = \", len(log_table[log_table['JumpType'] == 'Infinite Activity Jumps']))\n",
        "    plot_results(data)\n",
        "    return data, log_table\n",
        "\n",
        "\n",
        "# 5. Visualization Function\n",
        "def plot_results(data):\n",
        "    \"\"\"Visualizes market data with jump signals using Plotly.\"\"\"\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Price\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=data['Close'], mode='lines', name='Price', line=dict(color='blue')))\n",
        "\n",
        "    # Returns with Jump Signals\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=data['LogReturns'], mode='lines', name='Log Returns', line=dict(color='grey', width=1)))\n",
        "    jumps = data[data['JumpSignal'] == 1]\n",
        "    fig.add_trace(go.Scatter(x=jumps.index, y=jumps['LogReturns'], mode='markers', name='Detected Jumps', marker=dict(color='red', symbol='triangle-up', size=8)))\n",
        "\n",
        "    # Volatility\n",
        "    fig.add_trace(go.Scatter(x=data.index, y=data['MedRV'], mode='lines', name='MedRV', line=dict(color='purple')))\n",
        "\n",
        "    fig.update_layout(title='Market Price and Jump Detection', xaxis_title='Datetime', yaxis_title='Values', template='plotly_dark')\n",
        "    fig.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage for last 30 days\n",
        "    data = main(file_path=\"/content/NYFANG_1min.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt8J9i-Li0WG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}